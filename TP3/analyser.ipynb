{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7354e835",
   "metadata": {},
   "source": [
    "# Analisador Léxico\n",
    "\n",
    "## Lista de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b95527f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens a serem usados\n",
    "token_exp = {\n",
    "    'SELECT': r'SELECT',\n",
    "    'WHERE': r'WHERE',\n",
    "    'LIMIT': r'LIMIT',\n",
    "    'VAR': r'\\?[A-Za-z_][A-Za-z0-9_]*',\n",
    "    'LB': r'\\{',\n",
    "    'RB': r'\\}',\n",
    "    'COLON': r':',\n",
    "    'NUM': r'[0-9]+',\n",
    "    'DOT': r'\\.',\n",
    "    'SKIP': r'[ \\t\\r\\n]+',\n",
    "    'A': r'\\ba\\b',\n",
    "    'STRING': r'\"[^\"]*\"',\n",
    "    'ALT': r'@[a-z]{2}',\n",
    "    'PREFIX': r'[A-Za-z_][A-Za-z0-9_]*'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33c1940",
   "metadata": {},
   "source": [
    "## Função Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93682e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(input_string):\n",
    "    recognized = []\n",
    "    reg_exp = '|'.join(f'(?P<{tok}>{exp})' for tok,exp in token_exp.items())\n",
    "    mo = re.finditer(reg_exp,input_string)\n",
    "\n",
    "    for m in mo:\n",
    "        dic = m.groupdict()\n",
    "        t = (\"UNKNOWN\", m.group(), m.span())\n",
    "        for name in token_exp.keys(): \n",
    "            if dic[name]:\n",
    "                t = (name, dic[name], m.span())\n",
    "        if not dic['SKIP'] and t[0] != 'UNKNOWN': \n",
    "            recognized.append(t)\n",
    "\n",
    "    return recognized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f290fa1",
   "metadata": {},
   "source": [
    "## Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf2e44fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SELECT', 'SELECT', (1, 7))\n",
      "('VAR', '?nome', (8, 13))\n",
      "('VAR', '?desc', (14, 19))\n",
      "('WHERE', 'WHERE', (20, 25))\n",
      "('LB', '{', (26, 27))\n",
      "('VAR', '?s', (28, 30))\n",
      "('A', 'a', (31, 32))\n",
      "('PREFIX', 'dbo', (33, 36))\n",
      "('COLON', ':', (36, 37))\n",
      "('PREFIX', 'MusicalArtist', (37, 50))\n",
      "('DOT', '.', (50, 51))\n",
      "('VAR', '?s', (52, 54))\n",
      "('PREFIX', 'foaf', (55, 59))\n",
      "('COLON', ':', (59, 60))\n",
      "('PREFIX', 'name', (60, 64))\n",
      "('STRING', '\"Chuck Berry\"', (65, 78))\n",
      "('ALT', '@en', (78, 81))\n",
      "('DOT', '.', (82, 83))\n",
      "('VAR', '?w', (84, 86))\n",
      "('PREFIX', 'dbo', (87, 90))\n",
      "('COLON', ':', (90, 91))\n",
      "('PREFIX', 'artist', (91, 97))\n",
      "('VAR', '?s', (98, 100))\n",
      "('DOT', '.', (100, 101))\n",
      "('VAR', '?w', (102, 104))\n",
      "('PREFIX', 'foaf', (105, 109))\n",
      "('COLON', ':', (109, 110))\n",
      "('PREFIX', 'name', (110, 114))\n",
      "('VAR', '?nome', (115, 120))\n",
      "('DOT', '.', (120, 121))\n",
      "('VAR', '?w', (122, 124))\n",
      "('PREFIX', 'dbo', (125, 128))\n",
      "('COLON', ':', (128, 129))\n",
      "('PREFIX', 'abstract', (129, 137))\n",
      "('VAR', '?desc', (138, 143))\n",
      "('RB', '}', (144, 145))\n",
      "('LIMIT', 'LIMIT', (146, 151))\n",
      "('NUM', '1000', (152, 156))\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT ?nome ?desc WHERE {\n",
    "?s a dbo:MusicalArtist.\n",
    "?s foaf:name \"Chuck Berry\"@en .\n",
    "?w dbo:artist ?s.\n",
    "?w foaf:name ?nome.\n",
    "?w dbo:abstract ?desc\n",
    "} LIMIT 1000\n",
    "'''\n",
    "\n",
    "for tok in tokenize(query):\n",
    "    print(tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8322ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SELECT', 'SELECT', (1, 7))\n",
      "('VAR', '?nome', (8, 13))\n",
      "('WHERE', 'WHERE', (15, 20))\n",
      "('LB', '{', (21, 22))\n",
      "('VAR', '?s', (23, 25))\n",
      "('A', 'a', (26, 27))\n",
      "('PREFIX', 'dbo', (28, 31))\n",
      "('COLON', ':', (31, 32))\n",
      "('PREFIX', 'MusicalArtist', (32, 45))\n",
      "('DOT', '.', (45, 46))\n",
      "('VAR', '?s', (47, 49))\n",
      "('PREFIX', 'foaf', (50, 54))\n",
      "('COLON', ':', (54, 55))\n",
      "('PREFIX', 'name', (55, 59))\n",
      "('STRING', '\"Chuck Berry\"', (60, 73))\n",
      "('ALT', '@en', (73, 76))\n",
      "('DOT', '.', (77, 78))\n",
      "('RB', '}', (79, 80))\n",
      "('LIMIT', 'LIMIT', (81, 86))\n",
      "('NUM', '10', (87, 89))\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT ?nome  WHERE {\n",
    "?s a dbo:MusicalArtist.\n",
    "?s foaf:name \"Chuck Berry\"@en .\n",
    "} LIMIT 10\n",
    "'''\n",
    "\n",
    "for tok in tokenize(query):\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e043678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SELECT', 'SELECT', (1, 7))\n",
      "('VAR', '?nome', (8, 13))\n",
      "('WHERE', 'WHERE', (15, 20))\n",
      "('LB', '{', (21, 22))\n",
      "('VAR', '?s', (23, 25))\n",
      "('A', 'a', (26, 27))\n",
      "('PREFIX', 'dbo', (28, 31))\n",
      "('COLON', ':', (31, 32))\n",
      "('PREFIX', 'MusicalArtist', (32, 45))\n",
      "('DOT', '.', (45, 46))\n",
      "('VAR', '?s', (47, 49))\n",
      "('PREFIX', 'foaf', (50, 54))\n",
      "('COLON', ':', (54, 55))\n",
      "('PREFIX', 'name', (55, 59))\n",
      "('STRING', '\"Chuck Berry\"', (60, 73))\n",
      "('ALT', '@en', (73, 76))\n",
      "('DOT', '.', (77, 78))\n",
      "('RB', '}', (79, 80))\n",
      "('PREFIX', 'LIM67IT', (81, 88))\n",
      "('NUM', '10', (89, 91))\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT ?nome  WHERE {\n",
    "?s a dbo:MusicalArtist.\n",
    "?s foaf:name \"Chuck Berry\"@en .\n",
    "} LIM67IT 10\n",
    "'''\n",
    "\n",
    "for tok in tokenize(query):\n",
    "    print(tok)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
